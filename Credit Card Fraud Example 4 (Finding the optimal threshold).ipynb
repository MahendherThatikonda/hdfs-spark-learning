{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark notebook ###\n",
    "\n",
    "Follow the instructions on the computing resources page to start a cluster and open this notebook.\n",
    "\n",
    "**Steps**\n",
    "\n",
    "1. Connect to the Windows server using Windows App.\n",
    "2. Connect to Kubernetes.\n",
    "3. Start Jupyter and open this notebook from Jupyter in order to connect to Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to import pyspark and to define start_spark() and stop_spark()\n",
    "\n",
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "import getpass\n",
    "import pandas\n",
    "import pyspark\n",
    "import random\n",
    "import re\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "# Constants used to interact with Azure Blob Storage using the hdfs command or Spark\n",
    "\n",
    "global username\n",
    "\n",
    "username = re.sub('@.*', '', getpass.getuser())\n",
    "\n",
    "\n",
    "# Functions used below\n",
    "\n",
    "def dict_to_html(d):\n",
    "    \"\"\"Convert a Python dictionary into a two column table for display.\n",
    "    \"\"\"\n",
    "\n",
    "    html = []\n",
    "\n",
    "    html.append(f'<table width=\"100%\" style=\"width:100%; font-family: monospace;\">')\n",
    "    for k, v in d.items():\n",
    "        html.append(f'<tr><td style=\"text-align:left;\">{k}</td><td>{v}</td></tr>')\n",
    "    html.append(f'</table>')\n",
    "\n",
    "    return ''.join(html)\n",
    "\n",
    "\n",
    "def show_as_html(df, n=20):\n",
    "    \"\"\"Leverage existing pandas jupyter integration to show a spark dataframe as html.\n",
    "    \n",
    "    Args:\n",
    "        n (int): number of rows to show (default: 20)\n",
    "    \"\"\"\n",
    "\n",
    "    display(df.limit(n).toPandas())\n",
    "\n",
    "    \n",
    "def display_spark():\n",
    "    \"\"\"Display the status of the active Spark session if one is currently running.\n",
    "    \"\"\"\n",
    "    \n",
    "    if 'spark' in globals() and 'sc' in globals():\n",
    "\n",
    "        name = sc.getConf().get(\"spark.app.name\")\n",
    "\n",
    "        html = [\n",
    "            f'<p><b>Spark</b></p>',\n",
    "            f'<p>The spark session is <b><span style=\"color:green\">active</span></b>, look for <code>{name}</code> under the running applications section in the Spark UI.</p>',\n",
    "            f'<ul>',\n",
    "            f'<li><a href=\"http://localhost:{sc.uiWebUrl.split(\":\")[-1]}\" target=\"_blank\">Spark Application UI</a></li>',\n",
    "            f'</ul>',\n",
    "            f'<p><b>Config</b></p>',\n",
    "            dict_to_html(dict(sc.getConf().getAll())),\n",
    "            f'<p><b>Notes</b></p>',\n",
    "            f'<ul>',\n",
    "            f'<li>The spark session <code>spark</code> and spark context <code>sc</code> global variables have been defined by <code>start_spark()</code>.</li>',\n",
    "            f'<li>Please run <code>stop_spark()</code> before closing the notebook or restarting the kernel or kill <code>{name}</code> by hand using the link in the Spark UI.</li>',\n",
    "            f'</ul>',\n",
    "        ]\n",
    "        display(HTML(''.join(html)))\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        html = [\n",
    "            f'<p><b>Spark</b></p>',\n",
    "            f'<p>The spark session is <b><span style=\"color:red\">stopped</span></b>, confirm that <code>{username} (notebook)</code> is under the completed applications section in the Spark UI.</p>',\n",
    "            f'<ul>',\n",
    "            f'<li><a href=\"\" target=\"_blank\">Spark UI</a></li>',\n",
    "            f'</ul>',\n",
    "        ]\n",
    "        display(HTML(''.join(html)))\n",
    "\n",
    "\n",
    "# Functions to start and stop spark\n",
    "\n",
    "def start_spark(executor_instances=2, executor_cores=1, worker_memory=1, master_memory=1):\n",
    "    \"\"\"Start a new Spark session and define globals for SparkSession (spark) and SparkContext (sc).\n",
    "    \n",
    "    Args:\n",
    "        executor_instances (int): number of executors (default: 2)\n",
    "        executor_cores (int): number of cores per executor (default: 1)\n",
    "        worker_memory (float): worker memory (default: 1)\n",
    "        master_memory (float): master memory (default: 1)\n",
    "    \"\"\"\n",
    "\n",
    "    global spark\n",
    "    global sc\n",
    "\n",
    "    cores = executor_instances * executor_cores\n",
    "    partitions = cores * 4\n",
    "    port = 4000 + random.randint(1, 999)\n",
    "\n",
    "    spark = (\n",
    "        SparkSession.builder\n",
    "        .config(\"spark.driver.extraJavaOptions\", f\"-Dderby.system.home=/tmp/{username}/spark/\")\n",
    "        .config(\"spark.dynamicAllocation.enabled\", \"false\")\n",
    "        .config(\"spark.executor.instances\", str(executor_instances))\n",
    "        .config(\"spark.executor.cores\", str(executor_cores))\n",
    "        .config(\"spark.cores.max\", str(cores))\n",
    "        .config(\"spark.driver.memory\", f'{master_memory}g')\n",
    "        .config(\"spark.executor.memory\", f'{worker_memory}g')\n",
    "        .config(\"spark.driver.maxResultSize\", \"0\")\n",
    "        .config(\"spark.sql.shuffle.partitions\", str(partitions))\n",
    "        .config(\"spark.kubernetes.container.image\", \"\")\n",
    "        .config(\"spark.kubernetes.container.image.pullPolicy\", \"IfNotPresent\")\n",
    "        .config(\"spark.kubernetes.memoryOverheadFactor\", \"0.3\")\n",
    "        .config(\"spark.memory.fraction\", \"0.1\")\n",
    "        .config(\"spark.app.name\", f\"{username} (notebook)\")\n",
    "        .getOrCreate()\n",
    "    )\n",
    "    sc = SparkContext.getOrCreate()\n",
    "    \n",
    "    display_spark()\n",
    "\n",
    "    \n",
    "def stop_spark():\n",
    "    \"\"\"Stop the active Spark session and delete globals for SparkSession (spark) and SparkContext (sc).\n",
    "    \"\"\"\n",
    "\n",
    "    global spark\n",
    "    global sc\n",
    "\n",
    "    if 'spark' in globals() and 'sc' in globals():\n",
    "\n",
    "        spark.stop()\n",
    "\n",
    "        del spark\n",
    "        del sc\n",
    "\n",
    "    display_spark()\n",
    "\n",
    "\n",
    "# Make css changes to improve spark output readability\n",
    "\n",
    "html = [\n",
    "    '<style>',\n",
    "    'pre { white-space: pre !important; }',\n",
    "    'table.dataframe td { white-space: nowrap !important; }',\n",
    "    'table.dataframe thead th:first-child, table.dataframe tbody th { display: none; }',\n",
    "    '</style>',\n",
    "]\n",
    "display(HTML(''.join(html)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credit Card Fraud ###\n",
    "\n",
    "The credit card fraud dataset is relatively simple, with numeric features that have been anonymised using PCA. There is however significant class imbalance with only 492 examples of fraud out of 284,807 transactions in total. This requires careful handling and makes evaluating the performance of the model hard.\n",
    "\n",
    "**Sections**\n",
    "\n",
    "- [Data](#Data)\n",
    "- [Finding the optimal threshold](#Finding-the-optimal-threshold)\n",
    "\n",
    "**Key points**\n",
    "\n",
    "- You can use `sc.getConf()` to calculate the ideal number of partitions for the resources you have allocated.\n",
    "- The `randomSplit` method will return a different random split every time the output is used unless the random seed is specified or the output is cached.\n",
    "- We can write functions to extract snippets of code that we want to use more than once and we can customize their behaviour with keyword arguments.\n",
    "  - `with_custom_prediction(pred, threshold)`\n",
    "  - `show_class_balance(data, name)`\n",
    "  - `show_metrics(pred, threshold)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to start a spark session in this notebook\n",
    "\n",
    "start_spark(executor_instances=2, executor_cores=1, worker_memory=4, master_memory=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark imports\n",
    "\n",
    "from pyspark.sql import Row, DataFrame, Window, functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other imports to be used locally\n",
    "\n",
    "import datetime\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.set_printoptions(edgeitems=5, threshold=100, precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def show_class_balance(data, name=\"data\", labelCol=\"label\"):\n",
    "    \"\"\"Helper function to show class balance based on label.\n",
    "    \n",
    "    Note that this function does not return anything.\n",
    "\n",
    "    Args:\n",
    "        data (pyspark.sql.DataFrame): datafame with label\n",
    "        name (str): name to print above metrics for readability \n",
    "        labelCol (str): label column name\n",
    "    \"\"\"\n",
    "\n",
    "    total = data.count()\n",
    "    counts = data.groupBy(labelCol).count().toPandas()\n",
    "    counts[\"ratio\"] = counts[\"count\"] / total\n",
    "\n",
    "    print(f'Class balance [{name}]')\n",
    "    print(f'')\n",
    "    print(f'total:   {total}')\n",
    "    print(f'counts:')\n",
    "    print(counts)\n",
    "    print(f'')\n",
    "\n",
    "    \n",
    "def with_custom_prediction(\n",
    "    pred,\n",
    "    threshold,\n",
    "    probabilityCol=\"probability\",\n",
    "    customPredictionCol=\"customPrediction\",\n",
    "):\n",
    "    \"\"\"Helper function to select a custom prediction column for a custom classification threshold.\n",
    "    \n",
    "    Args:\n",
    "        pred (pyspark.sql.DataFrame): datafame with column for probability \n",
    "        threshold (float): classification threshold\n",
    "        probabilityCol (str): probability column name\n",
    "        customPredictionCol (str): new custom prediction column name\n",
    "    \n",
    "    Returns:\n",
    "        pred (pyspark.sql.DataFrame): dataframe with new colum for custom prediction\n",
    "    \"\"\"\n",
    "\n",
    "    classification_udf = F.udf(lambda x: int(x[1] > threshold), IntegerType())\n",
    "    \n",
    "    return pred.withColumn(customPredictionCol, classification_udf(F.col(probabilityCol)))\n",
    "\n",
    "\n",
    "def show_metrics(\n",
    "    pred,\n",
    "    name=\"data\",\n",
    "    threshold=0.5,\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    rawPredictionCol=\"rawPrediction\",\n",
    "    probabilityCol=\"probability\",\n",
    "):\n",
    "    \"\"\"Helper function to evaluate and show metrics based on a custom classification threshold.\n",
    "    \n",
    "    Note that this function does not return anything.\n",
    "    \n",
    "    Args:\n",
    "        pred (pyspark.sql.DataFrame): datafame with column for probability \n",
    "        name (str): name to print above metrics for readability \n",
    "        threshold (float): classification threshold (default: 0.5)\n",
    "        predictionCol (str): prediction column name\n",
    "        rawPredictionCol (str): raw prediction column name\n",
    "        probabilityCol (str): probability column name\n",
    "    \"\"\"\n",
    "\n",
    "    if threshold != 0.5:\n",
    "\n",
    "        predictionCol = \"customPrediction\"\n",
    "        pred = with_custom_prediction(pred, threshold, probabilityCol=probabilityCol, customPredictionCol=predictionCol)\n",
    "\n",
    "    total = pred.count()\n",
    "\n",
    "    nP_actual = pred.filter((F.col(labelCol) == 1)).count()\n",
    "    nN_actual = pred.filter((F.col(labelCol) == 0)).count()\n",
    "\n",
    "    nP = pred.filter((F.col(predictionCol) == 1)).count()\n",
    "    nN = pred.filter((F.col(predictionCol) == 0)).count()\n",
    "    TP = pred.filter((F.col(predictionCol) == 1) & (F.col(labelCol) == 1)).count()\n",
    "    FP = pred.filter((F.col(predictionCol) == 1) & (F.col(labelCol) == 0)).count()\n",
    "    FN = pred.filter((F.col(predictionCol) == 0) & (F.col(labelCol) == 1)).count()\n",
    "    TN = pred.filter((F.col(predictionCol) == 0) & (F.col(labelCol) == 0)).count()\n",
    "\n",
    "    if TP + FP > 0:\n",
    "        precision = TP / (TP + FP)\n",
    "    else:\n",
    "        precision = 0\n",
    "        \n",
    "    recall = TP / (TP + FN)\n",
    "    accuracy = (TP + TN) / total\n",
    "\n",
    "    binary_evaluator = BinaryClassificationEvaluator(\n",
    "        rawPredictionCol=rawPredictionCol,\n",
    "        labelCol=labelCol,\n",
    "        metricName='areaUnderROC',\n",
    "    )\n",
    "    auroc = binary_evaluator.evaluate(pred)\n",
    "\n",
    "    print(f'Metrics [{name}]')\n",
    "    print(f'')\n",
    "    print(f'threshold: {threshold}')\n",
    "    print(f'')\n",
    "    print(f'total:     {total}')\n",
    "    print(f'')\n",
    "    print(f'nP actual: {nP_actual}')\n",
    "    print(f'nN actual: {nN_actual}')\n",
    "    print(f'')\n",
    "    print(f'nP:        {nP}')\n",
    "    print(f'nN:        {nN}')\n",
    "    print(f'')\n",
    "    print(f'TP         {TP}')\n",
    "    print(f'FP         {FP}')\n",
    "    print(f'FN         {FN}')\n",
    "    print(f'TN         {TN}')\n",
    "    print(f'')\n",
    "    print(f'precision: {precision:.8f}')\n",
    "    print(f'recall:    {recall:.8f}')\n",
    "    print(f'accuracy:  {accuracy:.8f}')\n",
    "    print(f'')\n",
    "    print(f'auroc:     {auroc:.8f}')\n",
    "\n",
    "\n",
    "def expand(x, s=0.05, d=0):\n",
    "    \"\"\"Expand a two element array about its center point by a relative scale or a fixed offset.\n",
    "    Args:\n",
    "        x (list|np.array): two element array\n",
    "        s (float): relative scale to expand array based on its width x[1] - x[0]\n",
    "        d (float): fixed offset to expand array\n",
    "    Returns:\n",
    "        x (np.array): expanded two element array\n",
    "    \"\"\"\n",
    "    \n",
    "    x = np.array(x)\n",
    "    d = d + s * (x[1] - x[0])\n",
    "    \n",
    "    return x + np.array([-d, d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine ideal number of partitions\n",
    "\n",
    "conf = sc.getConf()\n",
    "\n",
    "N = int(conf.get(\"spark.executor.instances\"))\n",
    "M = int(conf.get(\"spark.executor.cores\"))\n",
    "partitions = 4 * N * M\n",
    "\n",
    "print(f'ideal # partitions = {partitions}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data ###\n",
    "\n",
    "The credit card fraud dataset is stored in HDFS.\n",
    "\n",
    "We will load the dataset and then use `VectorAssembler` to combine the separate feature columns into the single vector column that is expected by most of the classes in the machine learning. \n",
    "\n",
    "**Key points**\n",
    "\n",
    "- The data in gzip compressed but Spark will automatically uncompress it as it is loaded.\n",
    "- The data has a header so we can infer schema conveniently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from HDFS\n",
    "\n",
    "fraud = (\n",
    "    spark.read.csv(\"hdfs:///data/fraud/manipulated.csv.gz\", header=True, inferSchema=True)\n",
    "    .repartition(partitions)\n",
    "    .cache()\n",
    ")\n",
    "\n",
    "fraud.printSchema()\n",
    "show_as_html(fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select what we need\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[col for col in fraud.columns if col.startswith(\"V\")],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "data = assembler.transform(fraud)\n",
    "data = data.select(\n",
    "    F.col('features'),\n",
    "    F.col('Class').alias('label'),\n",
    ")\n",
    "\n",
    "data.printSchema()\n",
    "show_as_html(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the optimal threshold ###\n",
    "\n",
    "You need to compute the cost of false positives and false negatives in the real world in order to evaluate the cost of the model for a specific threshold.\n",
    "\n",
    "**Key points**\n",
    "\n",
    "- You can parameterize these costs and vary them to see how they impact your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into test and training\n",
    "\n",
    "training, test = data.randomSplit([0.8, 0.2])\n",
    "training.cache()\n",
    "test.cache()\n",
    "\n",
    "show_class_balance(data, \"data\")\n",
    "show_class_balance(training, \"training\")\n",
    "show_class_balance(test, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "lr = LogisticRegression(featuresCol='features', labelCol='label')\n",
    "lr_model = lr.fit(training)\n",
    "\n",
    "pred = lr_model.transform(test)\n",
    "pred.cache()\n",
    "\n",
    "show_metrics(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def evaluate_metrics_and_cost_local(\n",
    "    pred_local, \n",
    "    threshold, \n",
    "    FP_cost, \n",
    "    FN_cost, \n",
    "    labelCol=\"label\", \n",
    "    predictionCol=\"customPrediction\", \n",
    "    rawPredictionCol=\"rawPrediction\",\n",
    "    probabilityCol=\"probability\",\n",
    "):\n",
    "    \"\"\"Helper function to evaluate and show metrics based on a custom classification threshold.\n",
    "    \n",
    "    Note that this function does not return anything.\n",
    "    \n",
    "    Args:\n",
    "        pred_local (pandas.DataFrame): local datafame with column for probability \n",
    "        threshold (float): classification threshold (default: 0.5)\n",
    "        FP_cost (float): cost of a false positive\n",
    "        FN_cost (float): cost of a false negative\n",
    "        labelCol (str): label column name\n",
    "        predictionCol (str): prediction column name\n",
    "        rawPredictionCol (str): raw prediction column name\n",
    "        probabilityCol (str): probability column name\n",
    "    \"\"\"\n",
    "\n",
    "    pred_local[predictionCol] = (pred_local[probabilityCol].apply(lambda x: x[1]) > threshold).astype(int)\n",
    "\n",
    "    total = pred_local.shape[0]\n",
    "\n",
    "    nP_actual = (pred_local[labelCol] == 1).sum()\n",
    "    nN_actual = (pred_local[labelCol] == 0).sum()\n",
    "\n",
    "    nP = ((pred_local[predictionCol] == 1)).sum()\n",
    "    nN = ((pred_local[predictionCol] == 0)).sum()\n",
    "    TP = ((pred_local[predictionCol] == 1) & (pred_local[labelCol] == 1)).sum()\n",
    "    FP = ((pred_local[predictionCol] == 1) & (pred_local[labelCol] == 0)).sum()\n",
    "    FN = ((pred_local[predictionCol] == 0) & (pred_local[labelCol] == 1)).sum()\n",
    "    TN = ((pred_local[predictionCol] == 0) & (pred_local[labelCol] == 0)).sum()\n",
    "\n",
    "    if TP + FP > 0:\n",
    "        precision = TP / (TP + FP)\n",
    "    else:\n",
    "        precision = 0\n",
    "        \n",
    "    recall = TP / (TP + FN)\n",
    "    accuracy = (TP + TN) / total\n",
    "\n",
    "    cost_total = FP_cost * FP + FN_cost * FN\n",
    "\n",
    "    return precision, recall, accuracy, cost_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect predictions locally\n",
    "\n",
    "pred_local = pred.select([\"label\", \"probability\"]).toPandas()  # select only the columns that we need\n",
    "\n",
    "# Define parameters\n",
    "\n",
    "FP_cost = 5  # e.g. time cost of a human to check a transaction by hand\n",
    "FN_cost = 100  # e.g. bank cost of reversing a fraudulent transaction, charged to the company\n",
    "\n",
    "N = 100\n",
    "\n",
    "# Compute metrics for a range of thresholds in [0, 1]\n",
    "\n",
    "thresholds = np.linspace(0, 1, N + 1)\n",
    "metrics = np.zeros((N + 1, 4))\n",
    "\n",
    "for i, threshold in enumerate(thresholds):\n",
    "    if (i & (i - 1) == 0) or i == N:\n",
    "        print(f\"{datetime.datetime.now()}: {i:04d}\")\n",
    "\n",
    "    metrics[i] = evaluate_metrics_and_cost_local(pred_local, threshold, FP_cost, FN_cost)\n",
    "\n",
    "# Extract and name arrays for plotting\n",
    "\n",
    "precision = metrics[:, 0]\n",
    "recall = metrics[:, 1]\n",
    "accuracy = metrics[:, 2]\n",
    "cost_total = metrics[:, 3]\n",
    "\n",
    "# Compute relative cost to make it easier to plot alongside precision, recall, and accuracy\n",
    "\n",
    "cost_rel = cost_total / cost_total.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the threshold corresponding to the minimum total cost and evaluate metrics for that threshold\n",
    "\n",
    "index = np.argmin(cost_total)\n",
    "threshold = thresholds[index]\n",
    "\n",
    "show_metrics(pred, threshold=threshold)\n",
    "print(f'')\n",
    "print(f'cost:      {cost_total[index]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot metrics against threshold\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9.825, 5))\n",
    "\n",
    "ax.plot(thresholds, accuracy, '-', color='orange', label=f'accuracy')\n",
    "ax.plot(thresholds, recall, '-', color='blue', label=f'recall')\n",
    "ax.plot(thresholds, precision, '-', color='red', label=f'precision')\n",
    "ax.plot(thresholds, cost_rel, '-', color='black', label=f'cost (relative)')\n",
    "\n",
    "ax.set_xlim(expand([0, 1], 0.05))\n",
    "ax.set_ylim(expand([0, 1], 0.10))\n",
    "\n",
    "ax.grid(alpha=0.5, linestyle='--')\n",
    "\n",
    "ax.set_title(\"Logistic regression metrics tradeoff based on changing threshold\")\n",
    "ax.set_xlabel(\"Threshold\")\n",
    "ax.set_ylabel(\"Metrics\")\n",
    "\n",
    "legend = ax.legend(borderaxespad=0.25, edgecolor='k', framealpha=1)\n",
    "legend.get_frame().set_linewidth(0.5)\n",
    "legend.get_frame().set_boxstyle('Square', pad=0.25)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Spark ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell before closing the notebook or kill your spark application by hand using the link in the Spark UI\n",
    "\n",
    "stop_spark()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
